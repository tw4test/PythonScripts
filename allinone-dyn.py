import subprocess
import time
import re
import os
import sqlite3
import subprocess
import threading
import time
from collections import deque
from datetime import datetime
import hashlib
from queue import Queue

from rich.progress import Progress, TextColumn, BarColumn, TimeElapsedColumn, TimeRemainingColumn
from rich.console import Console

import matplotlib.patches as patches
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
from matplotlib.gridspec import GridSpec
from matplotlib.widgets import Button, TextBox
import tkinter as tk
from tkinter import filedialog
import tkinter.messagebox as msgbox
from matplotlib import rcParams

def run_adb_command(cmd):
    full_cmd = ["adb"] + cmd
    try:
        result = subprocess.run(full_cmd, capture_output=True, text=True, encoding="utf-8", errors="replace", timeout=120)
        if result.returncode != 0:
            raise RuntimeError(f"ADB å‘½ä»¤å¤±æ•—: {' '.join(full_cmd)}\n{result.stderr.strip()}")
        return result.stdout.strip()
    except Exception as e:
        log(f"ADB åŸ·è¡ŒéŒ¯èª¤: {e}")
        raise

def adb_create_remote_folder(remote_path):
    log(f"ADB: å»ºç«‹é ç«¯ç›®éŒ„: {remote_path}")
    run_adb_command(["shell", "mkdir", "-p", remote_path])

def check_all_files_processed_with_retry(conn, max_retries=3):
    """æª¢æŸ¥æ˜¯å¦æ‰€æœ‰æ–‡ä»¶éƒ½å·²è™•ç† - é‡è©¦ç‰ˆæœ¬"""
    for attempt in range(max_retries):
        try:
            cur = conn.cursor()
            cur.execute("SELECT COUNT(*) FROM files WHERE status IN ('pending', 'processing')")
            unfinished_count = cur.fetchone()[0]
            if unfinished_count == 0:
                return True
            if attempt < max_retries - 1:
                time.sleep(0.2)
        except Exception as e:
            log(f"æª¢æŸ¥å®Œæˆç‹€æ…‹å¤±æ•— (å˜—è©¦ {attempt + 1}): {e}")
            if attempt < max_retries - 1:
                time.sleep(0.5)

# å˜—è©¦å°å…¥ rich æ¨¡å¡Š
try:
    from rich.progress import Progress, TextColumn, BarColumn, TimeElapsedColumn, TimeRemainingColumn
    from rich.console import Console
    RICH_AVAILABLE = True
except ImportError:
    RICH_AVAILABLE = False

# çµ±ä¸€çš„æ—¥èªŒå‡½æ•¸
def log(msg):
    """çµ±ä¸€çš„æ™‚é–“æˆ³æ—¥èªŒå‡½æ•¸"""
    timestamp = time.strftime("%H:%M:%S")
    print(f"[{timestamp}] {msg}")

# åˆå§‹åŒ– console å°è±¡
if RICH_AVAILABLE:
    console = Console()

    def rich_log(text):
        clean_text = re.sub(r'\[.*?\]', '', str(text))
        log(clean_text)
else:
    class SimpleConsole:
        def print(self, text, **kwargs):
            clean_text = re.sub(r'\[.*?\]', '', str(text))
            log(clean_text)
    console = SimpleConsole()

# è¨­å®šä¸­æ–‡å­—å‹ï¼Œè¦–ç³»çµ±èª¿æ•´
rcParams['font.family'] = ['Microsoft JhengHei']
rcParams['axes.unicode_minus'] = False

# åƒæ•¸èˆ‡å…¨å±€è®Šæ•¸
DB_PATH = "filetransfer_new.db"
REMOTE_ROOT = "/sdcard/ToProcess"
CAMERA_ROOT = "/sdcard/DCIM/Camera"
BATCH_PREFIX = "batch_"

# CPUæ•¸æ“šå’Œç‹€æ…‹
cpu_data = deque(maxlen=60)
cpu_status_lock = threading.Lock()

# åˆ†é›¢çš„æ§åˆ¶ç‹€æ…‹
cpu_monitoring = False          # CPUç›£æ§ç‹€æ…‹
batch_processing = False        # æ‰¹æ¬¡è™•ç†ç‹€æ…‹

status_text = "Idle"
params = {
    'batch_size': 500,
    'batch_size_gb': 90,
    'cpu_threshold': 50.0,
    'monitor_interval': 2.0,
    'backup_stable_time': 30,  # 30 secs is ok
    'quick_backup_detection': False,  # Disabled smart detect
    'duplicate_handling': 'smart',
    'hash_small_files_only': True,
    'small_file_threshold': 50 * 1024 * 1024,
    'max_rounds': 9999
}

# æ§åˆ¶æ——æ¨™èˆ‡ç‹€æ…‹
cpu_active_flag = False
batch_processing_lock = threading.Lock()
batch_in_process = False
operation_lock = threading.Lock()

# /////////////////////////////////////////////////////////////////////////////
# UIç‹€æ…‹ç®¡ç†ç³»çµ±
class UIStateManager:
    """UIç‹€æ…‹ç®¡ç†å™¨"""

    def __init__(self):
        self.current_state = 'idle'  # idle, processing, scanning
        self.state_lock = threading.Lock()
        self.last_button_clicks = {}

    def can_perform_action(self, action, min_interval=2.0):
        """æª¢æŸ¥æ˜¯å¦å¯ä»¥åŸ·è¡Œæ“ä½œ"""
        current_time = time.time()

        with self.state_lock:
            # æª¢æŸ¥é»æ“Šé »ç‡
            last_click = self.last_button_clicks.get(action, 0)
            if current_time - last_click < min_interval:
                return False, f"è«‹ç­‰å¾… {min_interval:.1f} ç§’å¾Œå†è©¦"

            # æª¢æŸ¥ç‹€æ…‹è¡çª
            if action == 'start_transfer':
                if self.current_state in ['processing', 'scanning']:
                    return False, f"ç•¶å‰ç‹€æ…‹ '{self.current_state}' ä¸å…è¨±é–‹å§‹å‚³è¼¸"

            elif action == 'scan_folder':
                if self.current_state == 'processing':
                    return False, "å‚³è¼¸é€²è¡Œä¸­ï¼Œç„¡æ³•æƒæè³‡æ–™å¤¾"

            elif action == 'refresh':
                if self.current_state == 'processing':
                    return False, "è™•ç†ä¸­ï¼Œå»ºè­°ç¨å¾Œåˆ·æ–°"

            # è¨˜éŒ„é»æ“Šæ™‚é–“
            self.last_button_clicks[action] = current_time
            return True, "æ“ä½œå…è¨±"

    def set_state(self, new_state):
        """è¨­ç½®æ–°ç‹€æ…‹"""
        with self.state_lock:
            old_state = self.current_state
            self.current_state = new_state
            log(f"[ç‹€æ…‹è®Šæ›´] {old_state} -> {new_state}")
            self.update_ui_for_state()

    def get_state(self):
        """ç²å–ç•¶å‰ç‹€æ…‹"""
        with self.state_lock:
            return self.current_state

    def update_ui_for_state(self):
        """æ ¹æ“šç‹€æ…‹æ›´æ–°UI"""
        state_configs = {
            'idle': {
                'start_button': {'text': 'é–‹å§‹å‚³è¼¸', 'color': 'lightgreen', 'enabled': True},
                'scan_button': {'text': 'æƒææœ¬åœ°è³‡æ–™å¤¾', 'color': 'lightblue', 'enabled': True},
                'stop_button': {'text': 'åœæ­¢å‚³è¼¸', 'color': 'lightgray', 'enabled': False},
                'refresh_button': {'color': 'lightyellow', 'enabled': True}
            },
            'processing': {
                'start_button': {'text': 'å‚³è¼¸ä¸­...', 'color': 'orange', 'enabled': False},
                'scan_button': {'text': 'æƒæå·²ç¦ç”¨', 'color': 'lightgray', 'enabled': False},
                'stop_button': {'text': 'åœæ­¢å‚³è¼¸', 'color': 'lightcoral', 'enabled': True},
                'refresh_button': {'color': 'lightgray', 'enabled': False}
            },
            'scanning': {
                'start_button': {'text': 'é–‹å§‹å‚³è¼¸', 'color': 'lightgray', 'enabled': False},
                'scan_button': {'text': 'æƒæä¸­...', 'color': 'orange', 'enabled': False},
                'stop_button': {'text': 'åœæ­¢å‚³è¼¸', 'color': 'lightgray', 'enabled': False},
                'refresh_button': {'color': 'lightgray', 'enabled': False}
            }
        }

        config = state_configs.get(self.current_state, state_configs['idle'])
        self.apply_button_config(config)

    def apply_button_config(self, config):
        """æ‡‰ç”¨æŒ‰éˆ•é…ç½®"""
        try:
            # æ›´æ–°é–‹å§‹æŒ‰éˆ•
            start_config = config.get('start_button', {})
            if 'text' in start_config:
                button_start.label.set_text(start_config['text'])
            if 'color' in start_config:
                button_start.color = start_config['color']
                button_start.hovercolor = start_config['color']

            # æ›´æ–°æƒææŒ‰éˆ•
            scan_config = config.get('scan_button', {})
            if 'text' in scan_config:
                button_scan.label.set_text(scan_config['text'])
            if 'color' in scan_config:
                button_scan.color = scan_config['color']
                button_scan.hovercolor = scan_config['color']

            # æ›´æ–°åœæ­¢æŒ‰éˆ•
            stop_config = config.get('stop_button', {})
            if 'text' in stop_config:
                button_stop.label.set_text(stop_config['text'])
            if 'color' in stop_config:
                button_stop.color = stop_config['color']
                button_stop.hovercolor = stop_config['color']

            # æ›´æ–°åˆ·æ–°æŒ‰éˆ•
            refresh_config = config.get('refresh_button', {})
            if 'color' in refresh_config:
                button_refresh.color = refresh_config['color']
                button_refresh.hovercolor = refresh_config['color']

            # é‡ç¹ªç•Œé¢
            fig.canvas.draw_idle()

        except Exception as e:
            log(f"[UIéŒ¯èª¤] æ›´æ–°æŒ‰éˆ•ç‹€æ…‹å¤±æ•—: {e}")

# å‰µå»ºå…¨å±€ç‹€æ…‹ç®¡ç†å™¨
ui_state = UIStateManager()

# /////////////////////////////////////////////////////////////////////////////
# Storage-Aware Batch Manager
class StorageAwareBatchManager:
    """Storage-aware batch manager with dynamic sizing"""
    
    def __init__(self, conn):
        self.conn = conn
        self.current_batch_id = None
        self.batch_start_time = None
        self.batch_files = []
        self.batch_total_size = 0
        self.successful_pushes = 0
        
        # Storage management
        self.min_batch_size_gb = 5   # Minimum viable batch
        self.max_batch_size_gb = params.get('batch_size_gb', 90)
        self.storage_buffer_gb = 10  # Always keep 10GB free
        self.last_storage_check = 0
        self.storage_check_interval = 15  # Check every 15 seconds
        
    def get_phone_storage_info(self):
        """Get detailed phone storage information"""
        try:
            # Method 1: Use df command
            output = run_adb_command(['shell', 'df', '/sdcard'])
            
            for line in output.strip().split('\n'):
                if '/sdcard' in line or '/storage/emulated' in line:
                    parts = line.split()
                    if len(parts) >= 4:
                        # df output: Filesystem 1K-blocks Used Available Use% Mounted
                        total_kb = int(parts[1])
                        available_kb = int(parts[3])
                        used_kb = total_kb - available_kb
                        
                        return {
                            'total_gb': total_kb / (1024 * 1024),
                            'available_gb': available_kb / (1024 * 1024),
                            'used_gb': used_kb / (1024 * 1024),
                            'used_percent': (used_kb / total_kb) * 100 if total_kb > 0 else 0
                        }
            
            return None
            
        except Exception as e:
            log(f"[å­˜å‚¨æ£€æŸ¥] è·å–å­˜å‚¨ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def calculate_safe_batch_size_adaptive(self, parallel_mode=True):
        """Calculate safe batch size with adaptive logic"""
        current_time = time.time()
        
        # Rate limit storage checks
        if current_time - self.last_storage_check < self.storage_check_interval:
            return min(self.max_batch_size_gb, params.get('batch_size_gb', 90))
        
        self.last_storage_check = current_time
        storage_info = self.get_phone_storage_info()
        
        if not storage_info:
            console.print("[yellow]âš  æ— æ³•è·å–å­˜å‚¨ä¿¡æ¯ï¼Œä½¿ç”¨ä¿å®ˆæ‰¹æ¬¡å¤§å°[/yellow]")
            return self.min_batch_size_gb * 2  # Conservative fallback
        
        available_gb = storage_info['available_gb']
        used_percent = storage_info['used_percent']
        
        console.print(f"[blue]ğŸ“± å­˜å‚¨çŠ¶æ€: {available_gb:.1f}GB å¯ç”¨ ({used_percent:.1f}% å·²ç”¨)[/blue]")
        
        # Calculate safe space accounting for parallel processing
        reserve_space = self.storage_buffer_gb
        if parallel_mode:
            # Account for potential 2 batches + processing overhead
            usable_space = (available_gb - reserve_space) / 2.5
        else:
            # Single batch mode
            usable_space = available_gb - reserve_space
        
        # Apply size constraints
        safe_batch_size = max(self.min_batch_size_gb, usable_space)
        safe_batch_size = min(self.max_batch_size_gb, safe_batch_size)
        
        # Emergency reductions based on usage
        if used_percent > 95:
            safe_batch_size = self.min_batch_size_gb
            console.print(f"[red]ğŸš¨ å­˜å‚¨å±é™© ({used_percent:.1f}%)ï¼Œæœ€å°æ‰¹æ¬¡: {safe_batch_size}GB[/red]")
        elif used_percent > 90:
            safe_batch_size = min(safe_batch_size, self.min_batch_size_gb * 2)
            console.print(f"[yellow]âš  å­˜å‚¨ç´§å¼  ({used_percent:.1f}%)ï¼Œå‡å°‘æ‰¹æ¬¡: {safe_batch_size:.1f}GB[/yellow]")
        elif used_percent > 80:
            safe_batch_size = min(safe_batch_size, safe_batch_size * 0.8)
            console.print(f"[yellow]ğŸ“Š å­˜å‚¨è­¦å‘Š ({used_percent:.1f}%)ï¼Œè°ƒæ•´æ‰¹æ¬¡: {safe_batch_size:.1f}GB[/yellow]")
        else:
            console.print(f"[green]âœ… å­˜å‚¨å……è¶³ï¼Œæ‰¹æ¬¡å¤§å°: {safe_batch_size:.1f}GB[/green]")
        
        return safe_batch_size

    def start_new_batch(self):
        """é–‹å§‹æ–°çš„å‹•æ…‹æ‰¹æ¬¡"""
        self.current_batch_id = f"batch_{int(time.time())}_{os.getpid()}"
        self.batch_start_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        self.batch_files = []
        self.batch_total_size = 0
        self.successful_pushes = 0
        log(f"[å‹•æ…‹æ‰¹æ¬¡] é–‹å§‹æ‰¹æ¬¡: {self.current_batch_id}")
        return self.current_batch_id

    def get_next_file_batch(self, max_files=None, max_size_gb=None):
        """ç²å–ä¸‹ä¸€æ‰¹å¾…è™•ç†æ–‡ä»¶ (always use latest params)"""
        # Always use the latest values from params if not explicitly provided
        max_files = params.get('batch_size', 1000) if max_files is None else max_files
        max_size_gb = params.get('batch_size_gb', 90) if max_size_gb is None else max_size_gb

        max_size_bytes = max_size_gb * 1024 * 1024 * 1024

        cur = self.conn.cursor()
        cur.execute("""
            SELECT id, path, size
            FROM files
            WHERE status='pending'
            ORDER BY id ASC
            LIMIT ?
        """, (max_files * 2,))

        pending_files = cur.fetchall()

        if not pending_files:
            return []

        # å‹•æ…‹çµ„åˆæ‰¹æ¬¡
        selected_files = []
        current_size = 0

        for file_id, path, size in pending_files:
            if (len(selected_files) >= max_files or
                    current_size + size > max_size_bytes):
                break

            selected_files.append({
                'id': file_id,
                'path': path,
                'size': size
            })
            current_size += size

        self.batch_files = selected_files
        self.batch_total_size = current_size

        # è¨˜éŒ„æ‰¹æ¬¡æ­·å²
        if selected_files:
            try:
                cur.execute("""
                    INSERT INTO batch_history (virtual_batch_id, start_time, file_count, total_size)
                    VALUES (?, ?, ?, ?)
                """, (self.current_batch_id, self.batch_start_time,
                      len(selected_files), current_size))
                self.conn.commit()
            except Exception as e:
                log(f"[è¨˜éŒ„éŒ¯èª¤] ç„¡æ³•è¨˜éŒ„æ‰¹æ¬¡æ­·å²: {e}")
        log(f"[å‹•æ…‹æ‰¹æ¬¡] é¸æ“‡ {len(selected_files)} å€‹æ–‡ä»¶ï¼Œç¸½å¤§å° {current_size/1024/1024:.1f}MB")
        return selected_files
    
    def get_next_file_batch_with_storage_awareness(self, parallel_mode=True):
        """Get next batch with storage-aware sizing"""
        # Calculate safe batch size
        safe_batch_size_gb = self.calculate_safe_batch_size_adaptive(parallel_mode)
        
        # Pre-flight storage check
        storage_info = self.get_phone_storage_info()
        if storage_info:
            if storage_info['available_gb'] < (safe_batch_size_gb + self.storage_buffer_gb):
                console.print("[red]â¸ å­˜å‚¨ç©ºé—´ä¸è¶³ï¼Œç­‰å¾…æ¸…ç†[/red]")
                return []
        
        # Update current params with calculated size
        original_size = params.get('batch_size_gb', 90)
        if abs(safe_batch_size_gb - original_size) > 1:
            console.print(f"[cyan]ğŸ”„ åŠ¨æ€è°ƒæ•´: {original_size}GB â†’ {safe_batch_size_gb:.1f}GB[/cyan]")
        
        # Get batch with calculated size
        return self.get_next_file_batch(
            max_files=params.get('batch_size', 1000),
            max_size_gb=safe_batch_size_gb
        )
    
    def verify_storage_after_cleanup(self, expected_freed_gb):
        """Verify storage was actually freed after cleanup"""
        try:
            time.sleep(2)  # Wait for filesystem sync
            storage_info = self.get_phone_storage_info()
            
            if storage_info:
                available_gb = storage_info['available_gb']
                console.print(f"[blue]ğŸ“Š æ¸…ç†åå­˜å‚¨: {available_gb:.1f}GB å¯ç”¨[/blue]")
                
                # Check if we have reasonable space for next batch
                if available_gb > (self.min_batch_size_gb + self.storage_buffer_gb):
                    return True
                else:
                    console.print(f"[yellow]âš  æ¸…ç†åå­˜å‚¨ä»ä¸è¶³: {available_gb:.1f}GB[/yellow]")
                    return False
            return False
        except Exception as e:
            console.print(f"[red]å­˜å‚¨éªŒè¯å¤±è´¥: {e}[/red]")
            return False
    
    def emergency_storage_check(self):
        """Emergency check if storage is critically low"""
        storage_info = self.get_phone_storage_info()
        if storage_info:
            if storage_info['used_percent'] > 98:
                console.print("[red]ğŸš¨ å­˜å‚¨ä¸¥é‡ä¸è¶³ï¼Œå¼ºåˆ¶æš‚åœ[/red]")
                return False
            elif storage_info['available_gb'] < 2:
                console.print("[red]ğŸš¨ å¯ç”¨ç©ºé—´ä¸è¶³2GBï¼Œå¼ºåˆ¶æš‚åœ[/red]")
                return False
        return True

    def mark_file_pushed(self, file_path):
        """æ¨™è¨˜æ–‡ä»¶ç‚ºå·²æ¨é€ - éœé»˜ç‰ˆæœ¬"""
        cur = self.conn.cursor()
        push_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        try:
            # æª¢æŸ¥ push_time åˆ—æ˜¯å¦å­˜åœ¨
            cur.execute("PRAGMA table_info(files)")
            columns = {row[1] for row in cur.fetchall()}

            if 'push_time' in columns:
                cur.execute("""
                    UPDATE files SET status='pushed', push_time=?, updated_at=CURRENT_TIMESTAMP
                    WHERE path=?
                """, (push_time, file_path))
            else:
                cur.execute("""
                    UPDATE files SET status='pushed', updated_at=CURRENT_TIMESTAMP
                    WHERE path=?
                """, (file_path,))

            if cur.rowcount > 0:
                self.successful_pushes += 1
                self.conn.commit()
                return True
            else:
                return False

        except Exception as e:
            console.print(f"[red]æ•¸æ“šåº«éŒ¯èª¤: {e}[/red]")
            return False

    def mark_file_failed(self, file_path, error_msg=None):
        """æ¨™è¨˜æ–‡ä»¶æ¨é€å¤±æ•— - éœé»˜ç‰ˆæœ¬"""
        try:
            cur = self.conn.cursor()
            cur.execute("""
                UPDATE files SET status='failed', updated_at=CURRENT_TIMESTAMP
                WHERE path=?
            """, (file_path,))
            self.conn.commit()
        except Exception as e:
            console.print(f"[red]æ•¸æ“šåº«éŒ¯èª¤: {e}[/red]")

    def complete_batch(self, batch_status='completed'):
        """å®Œæˆç•¶å‰æ‰¹æ¬¡ - ä¿®å¾©ç‰ˆ (guard against zero-file batch)"""
        if not self.current_batch_id:
            return

        total_files = len(self.batch_files)
        if total_files == 0:
            log(f"[æ‰¹æ¬¡å®Œæˆ] {self.current_batch_id}: ç„¡æ–‡ä»¶ï¼Œæ‰¹æ¬¡ç•¥é (æˆåŠŸæ¨é€: {self.successful_pushes})")
            self.successful_pushes = 0
            self.current_batch_id = None
            self.batch_files = []
            return

        try:
            end_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

            cur = self.conn.cursor()
            cur.execute("""
                UPDATE batch_history
                SET end_time=?, success_count=?, status=?
                WHERE virtual_batch_id=?
            """, (end_time, self.successful_pushes, batch_status, self.current_batch_id))
            self.conn.commit()

            success_rate = (self.successful_pushes / total_files) * 100
            log(f"[æ‰¹æ¬¡å®Œæˆ] {self.current_batch_id}: {self.successful_pushes}/{total_files} ({success_rate:.1f}%)")

        except Exception as e:
            log(f"[æ‰¹æ¬¡è¨˜éŒ„éŒ¯èª¤] ç„¡æ³•æ›´æ–°æ‰¹æ¬¡ç‹€æ…‹: {e}")
        finally:
            # é‡ç½®ç‹€æ…‹
            self.current_batch_id = None
            self.batch_files = []
            self.successful_pushes = 0
# ...existing code...

# /////////////////////////////////////////////////////////////////////////////
# Safe Parallel Batch Scheduler with Storage Management
class SafeParallelBatchScheduler:
    """Safe parallel scheduler with comprehensive storage management"""
    
    def __init__(self, conn):
        self.conn = conn
        self.storage_manager = StorageAwareBatchManager(conn)
        self.push_queue = Queue(maxsize=1)  # More conservative queue
        self.running = False
        self.total_batches_pushed = 0
        self.total_batches_processed = 0
        
        # Thread management
        self.push_thread = None
        self.process_thread = None
        
    def _push_worker(self):
        """Enhanced push worker with storage monitoring"""
        consecutive_failures = 0
        max_failures = 3
        
        while self.running and batch_processing:
            try:
                # Emergency storage check
                if not self.storage_manager.emergency_storage_check():
                    console.print("[red]ğŸ›‘ å­˜å‚¨ç´§æ€¥æš‚åœï¼Œç­‰å¾…60ç§’[/red]")
                    time.sleep(60)
                    continue
                
                # Check if we can push (queue not full)
                if self.push_queue.qsize() == 0:
                    # Get storage-aware batch
                    file_batch = self.storage_manager.get_next_file_batch_with_storage_awareness(
                        parallel_mode=True
                    )
                    
                    if file_batch:
                        # Pre-push storage verification
                        batch_size_gb = sum(f['size'] for f in file_batch) / (1024**3)
                        
                        # Double-check storage before push
                        storage_info = self.storage_manager.get_phone_storage_info()
                        if storage_info:
                            required_space = batch_size_gb + self.storage_manager.storage_buffer_gb
                            if storage_info['available_gb'] < required_space:
                                console.print(f"[yellow]â¸ æ¨é€å‰æ£€æŸ¥: éœ€è¦{required_space:.1f}GBï¼Œä»…æœ‰{storage_info['available_gb']:.1f}GB[/yellow]")
                                time.sleep(30)
                                continue
                        
                        # Proceed with push
                        batch_id = self.storage_manager.start_new_batch()
                        console.print(f"[cyan]ğŸ“¤ æ¨é€æ‰¹æ¬¡ {self.total_batches_pushed + 1}: {len(file_batch)} æ–‡ä»¶ ({batch_size_gb:.1f}GB)[/cyan]")
                        
                        remote_temp_folder = f"{REMOTE_ROOT}/batch_temp_{int(time.time())}"
                        success_count = push_files_individually(
                            self.storage_manager, file_batch, remote_temp_folder
                        )
                        
                        if success_count > 0:
                            batch_info = {
                                'batch_id': batch_id,
                                'batch_manager': self.storage_manager,
                                'file_batch': file_batch,
                                'remote_temp_folder': remote_temp_folder,
                                'success_count': success_count,
                                'batch_size_gb': batch_size_gb
                            }
                            
                            try:
                                self.push_queue.put(batch_info, timeout=30)
                                self.total_batches_pushed += 1
                                consecutive_failures = 0
                                console.print(f"[green]âœ… æ‰¹æ¬¡ {self.total_batches_pushed} æ¨é€å®Œæˆ[/green]")
                            except:
                                console.print("[yellow]âš  å¤„ç†é˜Ÿåˆ—æ»¡ï¼Œç­‰å¾…å¤„ç†[/yellow]")
                                time.sleep(10)
                        else:
                            console.print(f"[red]âŒ æ‰¹æ¬¡æ¨é€å¤±è´¥: {batch_id}[/red]")
                            self.storage_manager.complete_batch('failed')
                            consecutive_failures += 1
                            
                            if consecutive_failures >= max_failures:
                                console.print(f"[red]ğŸ›‘ è¿ç»­{max_failures}æ¬¡æ¨é€å¤±è´¥ï¼Œæš‚åœæ¨é€[/red]")
                                time.sleep(120)
                                consecutive_failures = 0
                    else:
                        # No more files to process
                        if check_all_files_processed(self.conn):
                            console.print("[green]ğŸ“¤ æ‰€æœ‰æ–‡ä»¶æ¨é€å®Œæˆ[/green]")
                            break
                        time.sleep(5)
                else:
                    # Queue full, wait for processing
                    time.sleep(15)
                    
            except Exception as e:
                console.print(f"[red]æ¨é€çº¿ç¨‹é”™è¯¯: {e}[/red]")
                consecutive_failures += 1
                time.sleep(min(10 * consecutive_failures, 60))
                
    def _process_worker(self):
        """Enhanced process worker with cleanup verification"""
        while self.running and batch_processing:
            try:
                # Check CPU status
                with cpu_status_lock:
                    cpu_idle = not cpu_active_flag
                
                if cpu_idle and not self.push_queue.empty():
                    try:
                        batch_info = self.push_queue.get(timeout=5)
                        
                        console.print(f"[yellow]ğŸ“± å¤„ç†æ‰¹æ¬¡ {self.total_batches_processed + 1}: {batch_info['batch_id']}[/yellow]")
                        
                        # Move to Camera with storage verification
                        camera_folder = f"{CAMERA_ROOT}/batch_{int(time.time())}"
                        
                        if move_remote_folder_safe(batch_info['remote_temp_folder'], camera_folder):
                            mark_pushed_files_completed(self.conn, batch_info['file_batch'])
                            
                            console.print("[yellow]â³ ç­‰å¾… Google Photos å¤„ç†...[/yellow]")
                            backup_completed = wait_for_backup_complete()
                            
                            if backup_completed:
                                # Enhanced cleanup with verification
                                console.print(f"[cyan]ğŸ§¹ æ¸…ç† Camera ç›®å½•: {camera_folder}[/cyan]")
                                cleanup_camera_folder(camera_folder)
                                
                                # Verify cleanup freed space
                                if self.storage_manager.verify_storage_after_cleanup(batch_info['batch_size_gb']):
                                    self.total_batches_processed += 1
                                    batch_info['batch_manager'].complete_batch('completed')
                                    console.print(f"[green]âœ… æ‰¹æ¬¡ {self.total_batches_processed} å®Œæˆï¼Œå­˜å‚¨å·²é‡Šæ”¾[/green]")
                                else:
                                    console.print("[yellow]âš  æ¸…ç†éªŒè¯å¤±è´¥ï¼Œä½†æ ‡è®°ä¸ºå®Œæˆ[/yellow]")
                                    self.total_batches_processed += 1
                                    batch_info['batch_manager'].complete_batch('completed')
                            else:
                                console.print("[yellow]âš  å¤‡ä»½è¢«ä¸­æ–­[/yellow]")
                                batch_info['batch_manager'].complete_batch('interrupted')
                                self.total_batches_processed += 1
                        else:
                            console.print("[red]âŒ æ‰¹æ¬¡ç§»åŠ¨å¤±è´¥[/red]")
                            batch_info['batch_manager'].complete_batch('failed')
                            
                    except:
                        # Queue was empty, continue
                        pass
                        
                elif not cpu_idle:
                    time.sleep(params['monitor_interval'])
                else:
                    # No batch to process, wait
                    if self.total_batches_pushed > self.total_batches_processed:
                        time.sleep(2)
                    else:
                        if not self.running or not batch_processing:
                            break
                        time.sleep(5)
                        
            except Exception as e:
                console.print(f"[red]å¤„ç†çº¿ç¨‹é”™è¯¯: {e}[/red]")
                time.sleep(10)
                
    def start_safe_parallel_processing(self):
        """Start safe parallel processing"""
        if self.running:
            return True
            
        # Initial storage check
        storage_info = self.storage_manager.get_phone_storage_info()
        if storage_info:
            if storage_info['used_percent'] > 95:
                console.print("[red]âš  è­¦å‘Š: å­˜å‚¨ç©ºé—´ä¸¥é‡ä¸è¶³ï¼Œå»ºè®®å…ˆæ¸…ç†æ‰‹æœº[/red]")
                return False
            elif storage_info['available_gb'] < 15:
                console.print("[red]âš  è­¦å‘Š: å¯ç”¨ç©ºé—´å°‘äº15GBï¼Œä¸å»ºè®®å¹¶è¡Œå¤„ç†[/red]")
                return False
        
        self.running = True
        console.print("[bold green]ğŸš€ å®‰å…¨å¹¶è¡Œå¤„ç†å¯åŠ¨[/bold green]")
        
        # Start worker threads
        self.push_thread = threading.Thread(target=self._push_worker, daemon=True)
        self.process_thread = threading.Thread(target=self._process_worker, daemon=True)
        
        self.push_thread.start()
        self.process_thread.start()
        
        return True
        
    def stop_safe_parallel_processing(self):
        """Stop safe parallel processing"""
        self.running = False
        console.print("[yellow]â¹ åœæ­¢å®‰å…¨å¹¶è¡Œå¤„ç†[/yellow]")
        
    def get_status(self):
        """Get current processing status"""
        return {
            'running': self.running,
            'queue_size': self.push_queue.qsize(),
            'total_pushed': self.total_batches_pushed,
            'total_processed': self.total_batches_processed
        }

# /////////////////////////////////////////////////////////////////////////////
# Enhanced Parallel Processing Thread
def safe_parallel_batch_process_thread():
    """Safe parallel batch processing with storage management"""
    global batch_in_process, batch_processing
    
    try:
        conn = init_db()
        scheduler = SafeParallelBatchScheduler(conn)
        
        # Start safe parallel processing
        if not scheduler.start_safe_parallel_processing():
            console.print("[red]âŒ æ— æ³•å¯åŠ¨å¹¶è¡Œå¤„ç† - å­˜å‚¨ç©ºé—´ä¸è¶³[/red]")
            return
        
        # Monitor processing
        last_status_time = time.time()
        while batch_processing:
            status = scheduler.get_status()
            
            # Status reporting every 30 seconds
            if time.time() - last_status_time > 30:
                storage_info = scheduler.storage_manager.get_phone_storage_info()
                if storage_info:
                    console.print(f"[blue]ğŸ“Š è¿›åº¦: æ¨é€{status['total_pushed']}/å¤„ç†{status['total_processed']}, å­˜å‚¨:{storage_info['available_gb']:.1f}GB[/blue]")
                last_status_time = time.time()
            
            # Check completion
            if (status['total_pushed'] > 0 and 
                status['total_pushed'] == status['total_processed'] and 
                status['queue_size'] == 0):
                
                if check_all_files_processed(conn):
                    console.print(f"[bold green]ğŸ‰ å®‰å…¨å¹¶è¡Œå¤„ç†å®Œæˆ! å¤„ç†{status['total_processed']}ä¸ªæ‰¹æ¬¡[/bold green]")
                    show_completion_notification(status['total_processed'])
                    break
                    
            time.sleep(3)
            
        scheduler.stop_safe_parallel_processing()
        conn.close()
        
    except Exception as e:
        console.print(f"[red]å®‰å…¨å¹¶è¡Œå¤„ç†é”™è¯¯: {e}[/red]")
    finally:
        batch_processing = False
        ui_state.set_state('idle')
        update_pending_count_text()

# /////////////////////////////////////////////////////////////////////////////
# Helper Functions for Storage Management
def get_current_batch_size():
    """Get current batch size for optimization"""
    try:
        conn = sqlite3.connect(DB_PATH)
        cur = conn.cursor()
        cur.execute("SELECT COUNT(*) FROM files WHERE status='pending'")
        pending_count = cur.fetchone()[0]
        conn.close()
        return pending_count
    except:
        return 0

def enhanced_batch_completion_check(conn, batch_manager, total_processed_batches):
    """Enhanced completion check with storage awareness"""
    try:
        if check_all_files_processed(conn):
            storage_info = batch_manager.get_phone_storage_info() if hasattr(batch_manager, 'get_phone_storage_info') else None
            
            console.print(f"[bold green]ğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼æ€»å…±å¤„ç† {total_processed_batches} ä¸ªæ‰¹æ¬¡[/bold green]")
            
            if storage_info:
                console.print(f"[blue]ğŸ“± æœ€ç»ˆå­˜å‚¨çŠ¶æ€: {storage_info['available_gb']:.1f}GB å¯ç”¨ ({storage_info['used_percent']:.1f}% å·²ç”¨)[/blue]")
            
            show_completion_notification(total_processed_batches)
            return True
        return False
    except Exception as e:
        console.print(f"[red]å®Œæˆæ£€æŸ¥é”™è¯¯: {e}[/red]")
        return False

# /////////////////////////////////////////////////////////////////////////////
# Updated UI Callbacks for Safe Parallel Processing
def on_start_safe_parallel(event):
    """Start safe parallel processing"""
    apply_params_from_ui()
    
    can_start, message = ui_state.can_perform_action('start_transfer', 3.0)
    if not can_start:
        print(f"[é˜²æŠ¤] {message}")
        return

    global batch_processing
    if batch_processing:
        print("[æç¤º] ä¼ è¾“å·²åœ¨è¿›è¡Œä¸­")
        return

    # Check prerequisites
    pending_count = query_pending_files_count()
    if pending_count == 0:
        print("[æç¤º] æ²¡æœ‰å¾…å¤„ç†æ–‡ä»¶ï¼Œè¯·å…ˆæ‰«æèµ„æ–™å¤¹")
        return

    # Ensure CPU monitoring
    if not cpu_monitoring:
        print("[è­¦å‘Š] CPUç›‘æ§æœªå¯åŠ¨ï¼Œæ­£åœ¨è‡ªåŠ¨å¯åŠ¨...")
        auto_start_cpu_monitoring()
        time.sleep(1)

    # Check ADB
    try:
        run_adb_command(['devices'])
        print("[æ£€æŸ¥] ADBè¿æ¥æ­£å¸¸")
    except Exception as e:
        print(f"[é”™è¯¯] ADBè¿æ¥å¤±è´¥: {e}")
        return

    ui_state.set_state('processing')
    batch_processing = True
    
    log("[UI] å¯åŠ¨å®‰å…¨å¹¶è¡Œæ‰¹æ¬¡å¤„ç†")
    threading.Thread(target=safe_parallel_batch_process_thread, daemon=True).start()
    
    print(f"[æˆåŠŸ] å®‰å…¨å¹¶è¡Œå¤„ç†å·²å¯åŠ¨ï¼Œå¾…å¤„ç†: {pending_count}")

# /////////////////////////////////////////////////////////////////////////////
# Storage Monitoring UI Functions
def display_storage_status():
    """Display current storage status in console"""
    try:
        storage_manager = StorageAwareBatchManager(sqlite3.connect(DB_PATH))
        storage_info = storage_manager.get_phone_storage_info()
        
        if storage_info:
            console.print(f"[blue]ğŸ“± å½“å‰å­˜å‚¨çŠ¶æ€:[/blue]")
            console.print(f"  æ€»å®¹é‡: {storage_info['total_gb']:.1f}GB")
            console.print(f"  å¯ç”¨ç©ºé—´: {storage_info['available_gb']:.1f}GB")
            console.print(f"  å·²ç”¨ç©ºé—´: {storage_info['used_gb']:.1f}GB ({storage_info['used_percent']:.1f}%)")
            
            # Storage recommendations
            if storage_info['used_percent'] > 90:
                console.print("[red]âš  å»ºè®®: å­˜å‚¨ç©ºé—´ç´§å¼ ï¼Œå»ºè®®æ¸…ç†æ‰‹æœºå­˜å‚¨[/red]")
            elif storage_info['used_percent'] > 80:
                console.print("[yellow]ğŸ’¡ å»ºè®®: å­˜å‚¨ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œæ³¨æ„ç©ºé—´ç®¡ç†[/yellow]")
            else:
                console.print("[green]âœ… å­˜å‚¨ç©ºé—´å……è¶³[/green]")
        else:
            console.print("[red]âŒ æ— æ³•è·å–å­˜å‚¨ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥ADBè¿æ¥[/red]")
            
    except Exception as e:
        console.print(f"[red]å­˜å‚¨çŠ¶æ€æ£€æŸ¥å¤±è´¥: {e}[/red]")

def on_check_storage(event):
    """Check storage status button callback"""
    can_check, message = ui_state.can_perform_action('check_storage', 2.0)
    if not can_check:
        print(f"[é˜²æŠ¤] {message}")
        return
        
    display_storage_status()

# /////////////////////////////////////////////////////////////////////////////
# Updated Button Bindings and UI Layout
def setup_enhanced_ui():
    """Setup enhanced UI with storage management"""
    global button_start, button_storage_check
    
    # Update the start button to use safe parallel processing
    button_start.on_clicked(on_start_safe_parallel)
    
    # Add storage check button
    ax_storage_check = plt.axes([0.44, 0.12, 0.1, 0.05])
    button_storage_check = Button(ax_storage_check, 'æ£€æŸ¥å­˜å‚¨')
    button_storage_check.label.set_fontsize(10)
    button_storage_check.on_clicked(on_check_storage)
    
    return button_storage_check

# /////////////////////////////////////////////////////////////////////////////
# Enhanced Startup and Initialization
def enhanced_startup_initialization():
    """Enhanced startup with storage awareness"""
    log("[ç³»ç»Ÿå¯åŠ¨] æ­£åœ¨åˆå§‹åŒ–å­˜å‚¨æ„ŸçŸ¥ç³»ç»Ÿ...")
    
    # Test storage detection
    try:
        test_manager = StorageAwareBatchManager(sqlite3.connect(DB_PATH))
        storage_info = test_manager.get_phone_storage_info()
        
        if storage_info:
            log(f"[å­˜å‚¨æ£€æµ‹] æ‰‹æœºå­˜å‚¨: {storage_info['available_gb']:.1f}GB å¯ç”¨")
            if storage_info['used_percent'] > 90:
                log("[å­˜å‚¨è­¦å‘Š] æ‰‹æœºå­˜å‚¨ç©ºé—´ä¸è¶³ï¼Œå»ºè®®å…ˆæ¸…ç†")
        else:
            log("[å­˜å‚¨è­¦å‘Š] æ— æ³•æ£€æµ‹æ‰‹æœºå­˜å‚¨ï¼Œå°†ä½¿ç”¨ä¿å®ˆæ¨¡å¼")
            
    except Exception as e:
        log(f"[å­˜å‚¨é”™è¯¯] å­˜å‚¨æ£€æµ‹å¤±è´¥: {e}")
    
    log("[ç³»ç»Ÿå¯åŠ¨] å­˜å‚¨æ„ŸçŸ¥ç³»ç»Ÿå·²å°±ç»ª")

# /////////////////////////////////////////////////////////////////////////////
# Replace the existing main execution with enhanced version
if __name__ == "__main__":
    log("[ç³»ç»Ÿå¯åŠ¨] æ­£åœ¨åˆå§‹åŒ–...")

    # ä¿®å¤ç°æœ‰æ•°æ®åº«çµæ§‹
    log("[ç³»ç»Ÿå¯åŠ¨] æ£€æŸ¥å¹¶ä¿®å¤æ•°æ®åº“...")
    fix_existing_database()

    # åˆå§‹åŒ–æ•°æ®åº«
    conn = init_db()
    update_pending_count_text()
    conn.close()

    # åˆå§‹åŒ–UIçŠ¶æ€ç®¡ç†
    ui_state.set_state('idle')

    # Enhanced startup initialization
    enhanced_startup_initialization()

    # Setup enhanced UI
    button_storage_check = setup_enhanced_ui()

    # è‡ªåŠ¨å¯åŠ¨CPUç›‘æ§
    log("[ç³»ç»Ÿå¯åŠ¨] æ­£åœ¨å¯åŠ¨CPUç›‘æ§...")
    auto_start_cpu_monitoring()
    log("[ç³»ç»Ÿå¯åŠ¨] CPUç›‘æ§å·²å¯åŠ¨")
    
    # Enhanced startup messages
    log("[ç³»ç»Ÿæç¤º] ç‚¹å‡»'å¼€å§‹ä¼ è¾“'æŒ‰é’®å¼€å§‹å®‰å…¨å¹¶è¡Œæ‰¹æ¬¡å¤„ç†")
    log("[ç³»ç»Ÿæç¤º] UIçŠ¶æ€ç®¡ç†å·²å¯ç”¨ - é˜²æ­¢é‡å¤æ“ä½œ")
    log("[ç³»ç»Ÿè¯´æ˜] å­˜å‚¨æ„ŸçŸ¥æ‰¹æ¬¡ç®¡ç† - åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°")
    log("[ç³»ç»Ÿè¯´æ˜] å¹¶è¡Œå¤„ç†æ¨¡å¼ - æ¨é€ä¸å¤„ç†é‡å æ‰§è¡Œ")
    log("[å®‰å…¨ç‰¹æ€§] å­˜å‚¨ç©ºé—´ç›‘æ§ - é˜²æ­¢æ‰‹æœºå­˜å‚¨æº¢å‡º")

    # plt.tight_layout()
    plt.subplots_adjust()
    plt.show()            